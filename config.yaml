# General parameters
ENVIRONMENT: ctgov  # ctgov, ctxai_dev, ctxai_prod
DATA_PATH: raw_files  # Test/2/metadata/intervention/intervention_similar_trials_full.xlsx
SELECT_USER_ID_AND_PROJECT_ID_AUTOMATICALLY: True
USER_ID: example_user_id  # any string (overwritten if SELECT_USER_ID_AND_PROJECT_ID_AUTOMATICALLY == True and ENVIRONMENT == ctgov)
PROJECT_ID: example_project_id  # any string (overwritten if SELECT_USER_ID_AND_PROJECT_ID_AUTOMATICALLY == True and ENVIRONMENT == ctgov)
USER_FILTERING: null  # null, intervention, condition, intersection
OPTUNA_SAMPLER: tpe  # tpe (presumably better), random (seed presumably more stable)
RANDOM_STATE: 0123
LOAD_PARSED_DATA: false
LOAD_EMBEDDINGS: false  # set to false if you change CHOSEN_COND/ITRV_LVL/IDS
LOAD_BERTOPIC_RESULTS: false

# Prediction  parameters
PREDICTOR_TARGET_TYPES: [phase, status, study_duration, enrollment_count, operational_rate]
PREDICTOR_INPUT_TYPES: [random, cluster_ids, raw_embeddings]  # [random, reduced_embeddings, raw_medoids, reduced_medoids, raw_completes, reduced_completes]
PREDICTOR_EMBEDDING_MODEL_ID: pubmed-bert-sentence  # only with the best one from cluster analysis
BALANCE_PREDICTION_DATA: true
N_PREDICTION_OPTUNA_TRIALS: 100

# Eligibility criteria parsing parameters
NUM_PARSE_WORKERS: 19  # 0 for no multi processing
PARSED_DATA_HEADERS:
  - criteria paragraph
  - complexity
  - ct path
  - label
  - phases
  - conditions
  - condition_ids
  - intervention_ids
  - category
  - context
  - subcontext
  - individual criterion
MESH_CROSSWALK_PATH: utils/mesh_crosswalk.json
MESH_CROSSWALK_INVERTED_PATH: utils/mesh_crosswalk_inverted.json

# Eligibility criteria filtering parameters
CHOSEN_STATUSES: []  # [completed, suspended, withdrawn, terminated, unknown status] -> /!\ I ended up selecting only completed + terminated CTs
CHOSEN_CRITERIA: []  # [in]
CHOSEN_PHASES: []  # [phase2]
CHOSEN_COND_IDS: ["C01"]  # Infections [C01] // Neoplasms [C04] // Cardiovascular Diseases [C14] // Immune System Diseases [C20]
CHOSEN_ITRV_IDS: []  # [D02]
CHOSEN_COND_LVL: 2  # null to ignore
CHOSEN_ITRV_LVL: 1  # null to ignore
STATUS_MAP: null  # null to ignore
ADDITIONAL_NEGATIVE_FILTER: {}  # {} to ignore // used to remove some eligibility criteria based on key-value mapping

# Eligibility criteria embedding parameters
MAX_ELIGIBILITY_CRITERIA_SAMPLES: 2_000_000  # ct-gov has maximum 1740170 criteria (maximum, if no filter is applied)
EMBEDDING_BATCH_SIZE: 64
EMBEDDING_MODEL_ID_MAP:
  pubmed-bert-sentence: pritamdeka/S-PubMedBert-MS-MARCO
  bert-sentence: sentence-transformers/msmarco-bert-base-dot-v5
  pubmed-bert-token: microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext
  bert: bert-large-uncased
  # roberta: roberta-large
  # bioct-bert-token: domenicrosati/ClinicalTrialBioBert-NLI4CT
  # transformer-sentence: sentence-transformers/all-mpnet-base-v2

# Clustering hyper-optimization parameters
N_OPTUNA_TRIALS: 100
N_CLUSTER_MAX: 1000  # used to avoid extreme hyper-parameter combinations
OPTUNA_PARAM_RANGES:
  max_cluster_size_primary: [0.01, 0.050]
  min_cluster_size_primary: [0.0001, 0.001]
  min_samples_primary: [0.0, 0.001]
  cluster_selection_method_primary: [eom, leaf]
  alpha_primary: [0.1, 3.0]
  max_cluster_size_secondary: [0.10, 1.00]
  min_cluster_size_secondary: [0.00, 0.01]
  min_samples_secondary: [0.00, 0.01]
  cluster_selection_method_secondary: [eom, leaf]
  alpha_secondary: [0.1, 3.0]
  subclusterize: [true, false]

# Cluster generation parameters
DO_EVALUATE_CLUSTERING: true  # if true, will generate metrics for the clustering
CLUSTER_DIM_RED_ALGO: tsne  # pca, umap, tsne, null (umap advised here)
CLUSTER_RED_DIM: 2  # becomes full-dim if CLUSTER_DIM_RED_ALGO == null
CLUSTER_RDM_METRIC: null  # null, correlation, euclidean  # NOT USED FOR NOW

# Cluster representation parameters
PLOT_DIM_RED_ALGO: tsne  # pca, umap, tsne (tsne advised here)
PLOT_RED_DIM: 2  # 2 or 3 (dim = 3 cannot use CuML, i.e., is slow)
PLOT_RDM_METRIC: null  # null, correlation, euclidean  # NOT USED FOR NOW
N_ITER_MAX_TSNE: 10000
CLUSTER_REPRESENTATION_MODEL: null  # null, gpt -> null will just use bertopic's topic keywords
CLUSTER_REPRESENTATION_TOP_N_WORDS_PER_TOPIC: 5  # BERTopic default = 10
CLUSTER_REPRESENTATION_PATH_TO_OPENAI_API_KEY: utils/api-key.txt
CLUSTER_REPRESENTATION_GPT_PROMPT: |
  I have a topic that contains the following documents: 
  [DOCUMENTS]
  The topic is described by the following keywords: 
  [KEYWORDS]
  Based on the information above, extract a short but highly descriptive topic label of at most 5 words.
  Make sure it is in the following format: <topic type>: <topic label>, where <topic type> is either "Inclusion criterion: " or "Exclustion criterion: "
  