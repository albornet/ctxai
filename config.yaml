# General parameters
ENVIRONMENT: ctxai_dev  # ctgov, ctxai_dev, ctxai_prod
DATA_PATH: Test/1/metadata/intervention/intervention_similar_trials.xlsx
USER_ID: ctgov-user
PROJECT_ID: ctgov-project
RANDOM_STATE: 1234
LOAD_PARSED_DATA: false
LOAD_EMBEDDINGS: false
LOAD_BERTOPIC_RESULTS: false

# Eligibility criteria parsing parameters
NUM_PARSE_WORKERS: 19  # 0 for no multi processing
PARSED_DATA_HEADERS:
  - criteria paragraph
  - complexity
  - ct path
  - label
  - phases
  - conditions
  - condition_ids
  - intervention_ids
  - category
  - context
  - subcontext
  - individual criterion
MESH_CROSSWALK_PATH: utils/mesh_crosswalk.json
MESH_CROSSWALK_INVERTED_PATH: utils/mesh_crosswalk_inverted.json

# Eligibility criteria filtering parameters
CHOSEN_STATUSES: []  # [completed, terminated]  # [completed, suspended, withdrawn, terminated, unknown status]
CHOSEN_CRITERIA: []  # [in]
CHOSEN_PHASES: []  # [Phase 2]
CHOSEN_COND_IDS: []  # Infections [C01] // Neoplasms [C04] // Cardiovascular Diseases [C14] // Immune System Diseases [C20]
CHOSEN_ITRV_IDS: []  # [D02]
CHOSEN_COND_LVL: null  # 3  # null to ignore
CHOSEN_ITRV_LVL: null  # 4  # null to ignore
STATUS_MAP: null

# Eligibility criteria embedding parameters
MAX_ELIGIBILITY_CRITERIA_SAMPLES: 100_000  # to avoid dumping core
EMBEDDING_BATCH_SIZE: 64
EMBEDDING_MODEL_ID_MAP:
  pubmed-bert-sentence: pritamdeka/S-PubMedBert-MS-MARCO
  # transformer-sentence: sentence-transformers/all-mpnet-base-v2
  # bert-sentence: efederici/sentence-bert-base
  # pubmed-bert-token: microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext
  # bioct-bert-token: domenicrosati/ClinicalTrialBioBert-NLI4CT
  # roberta: roberta-large
  # bert: bert-large-uncased

# Clustering hyper-optimization parameters
OPTUNA_SAMPLER: tpe  # tpe (better), random (seed presumably more stable)
N_OPTUNA_TRIALS: 100
N_CLUSTER_MAX: 500  # used to avoid extreme hyper-parameter combinations
OPTUNA_PARAM_RANGES:
  max_cluster_size_primary: [0.01, 0.10]
  min_cluster_size_primary: [0.00, 0.01]
  min_samples_primary: [0.0, 0.01]
  cluster_selection_method_primary: [eom, leaf]
  alpha_primary: [0.1, 10.0]
  max_cluster_size_secondary: [0.10, 1.00]
  min_cluster_size_secondary: [0.00, 0.10]
  min_samples_secondary: [0.00, 0.01]
  cluster_selection_method_secondary: [eom, leaf]
  alpha_secondary: [0.1, 10.0]

# Cluster generation parameters
DO_EVALUATE_CLUSTERING: false  # if true, will generate metrics for the clustering
DO_SUBCLUSTERIZE: true  # if true, try to cluster further each computed cluster
CLUSTER_DIM_RED_ALGO: umap  # pca, umap, tsne, null (umap advised here)
CLUSTER_RED_DIM: 10  # becomes full-dim if CLUSTER_DIM_RED_ALGO == null
CLUSTER_RDM_METRIC: null  # null, correlation, euclidean  # NOT USED FOR NOW

# Cluster representation parameters
PLOT_DIM_RED_ALGO: tsne  # pca, umap, tsne (tsne advised here)
PLOT_RED_DIM: 2  # 2 or 3 (dim = 3 cannot use CuML, i.e., is slow)
PLOT_RDM_METRIC: null  # null, correlation, euclidean  # NOT USED FOR NOW
N_ITER_MAX_TSNE: 10000
CLUSTER_REPRESENTATION_MODEL: null  # null, gpt -> null will just use bertopic's topic keywords
CLUSTER_REPRESENTATION_TOP_N_WORDS_PER_TOPIC: 5  # BERTopic default = 10
CLUSTER_REPRESENTATION_PATH_TO_OPEAI_API_KEY: utils/api-key.txt
CLUSTER_REPRESENTATION_GPT_PROMPT: |
  I have a topic that contains the following documents: 
  [DOCUMENTS]
  The topic is described by the following keywords: 
  [KEYWORDS]
  Based on the information above, extract a short but highly descriptive topic label of at most 5 words.
  Make sure it is in the following format: <topic type>: <topic label>, where <topic type> is either "Inclusion criterion: " or "Exclustion criterion: "
  