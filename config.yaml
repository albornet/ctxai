# General parameters
USER_ID: null
PROJECT_ID: null
RANDOM_STATE: 1234
LOAD_PREPROCESSED_DATA: false
LOAD_EMBEDDINGS: false
LOAD_REDUCED_EMBEDDINGS: false
LOAD_OPTUNA_RESULTS: false
LOAD_CLUSTER_RESULTS: false
LOAD_CLUSTER_TITLES: false

# Directories and data format
RAW_INPUT_FORMAT: ctxai  # json, ctxai
BASE_DATA_DIR: data
PREPROCESSED_SUBDIR: preprocessed  # <BASE_DATA_DIR>/<PREPROCESSED_SUBDIR>
POSTPROCESSED_SUBDIR: postprocessed  # <BASE_DATA_DIR>/<POSTPROCESSED_SUBDIR>
RESULT_DIR: results

# Eligibility criteria pre-processing parameters
NUM_PARSE_WORKERS: 12  # 0 for no multi processing
PREPROCESSED_DATA_HEADERS:
  - criteria paragraph
  - complexity
  - ct path
  - label
  - phases
  - conditions
  - condition_ids
  - intervention_ids
  - category
  - context
  - subcontext
  - individual criterion
PREPROCESSED_FILE_MASK: "*criteria.csv"
MESH_CROSSWALK_NAME: mesh_crosswalk.json
MESH_CROSSWALK_INVERTED_NAME: mesh_crosswalk_inverted.json

# Eligibility criteria filtering parameters ([] to ignore filters)
CHOSEN_STATUSES: []  # [completed, terminated]  # [completed, suspended, withdrawn, terminated, unknown status]
CHOSEN_CRITERIA: []  # [in]
CHOSEN_PHASES: []  # [Phase 2]
CHOSEN_COND_IDS: []  # Infections [C01] // Neoplasms [C04] // Cardiovascular Diseases [C14] // Immune System Diseases [C20]
CHOSEN_ITRV_IDS: []  # [D02]
CHOSEN_COND_LVL: null  # 4  # None to ignore this one
CHOSEN_ITRV_LVL: null  # 3  # None to ignore this one
STATUS_MAP: null

# Eligibility criteria embedding parameters
MAX_ELIGIBILITY_CRITERIA_SAMPLES: 10_000_000  # just big number for now
EMBEDDING_BATCH_SIZE: 64
EMBEDDING_MODEL_ID_MAP:
  pubmed-bert-sentence: pritamdeka/S-PubMedBert-MS-MARCO
  # transformer-sentence: sentence-transformers/all-mpnet-base-v2
  # bert-sentence: efederici/sentence-bert-base
  # pubmed-bert-token: microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext
  # bioct-bert-token: domenicrosati/ClinicalTrialBioBert-NLI4CT
  # roberta: roberta-large
  # bert: bert-large-uncased

# Clustering hyper-optimization parameters
OPTUNA_SAMPLER: random  # tpe (better), random (seed more stable)
N_OPTUNA_TRIALS: 100
N_CLUSTER_MAX: 500  # used to avoid extreme hyper-parameter combinations
OPTUNA_PARAM_RANGES:
  max_cluster_size_primary: [0.01, 0.10]
  min_cluster_size_primary: [0.00, 0.01]
  min_samples_primary: [0.0, 0.01]
  cluster_selection_method_primary: [eom, leaf]
  alpha_primary: [0.1, 10.0]
  max_cluster_size_secondary: [0.10, 1.00]
  min_cluster_size_secondary: [0.00, 0.10]
  min_samples_secondary: [0.00, 0.01]
  cluster_selection_method_secondary: [eom, leaf]
  alpha_secondary: [0.1, 10.0]

# Cluster generation parameters
CLUSTER_DIM_RED_ALGO: umap  # pca, umap, tsne, null (umap advised here)
CLUSTER_RED_DIM: 10  # becomes full-dim if CLUSTER_DIM_RED_ALGO == null
CLUSTER_RDM_METRIC: null  # null, correlation, euclidean  # NOT USED FOR NOW
N_ITER_MAX_TSNE: 10000
DO_SUBCLUSTERIZE: false  # if true, try to cluster further each computed cluster

# Cluster representation parameters
PLOT_DIM_RED_ALGO: tsne  # pca, umap, tsne (tsne advised here)
PLOT_RED_DIM: 2  # 2 or 3 (dim = 3 cannot use CuML, i.e., is slow)
PLOT_RDM_METRIC: null  # null, correlation, euclidean  # NOT USED FOR NOW
CLUSTER_REPRESENTATION_MODEL: null  # null, gpt -> null will just use bertopic's topic keywords
CLUSTER_REPRESENTATION_TOP_N_WORDS_PER_TOPIC: 5  # BERTopic default = 10
CLUSTER_REPRESENTATION_GPT_PROMPT: |
  I have a topic that contains the following documents: 
  [DOCUMENTS]
  The topic is described by the following keywords: 
  [KEYWORDS]
  Based on the information above, extract a short but highly descriptive topic label of at most 5 words.
  Make sure it is in the following format: topic: <topic label>
  